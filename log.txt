root@d4a1a9ad5ff4:/workspace# cd DL-healthcare
root@d4a1a9ad5ff4:/workspace/DL-healthcare# python src/main.py
Traceback (most recent call last):
  File "/workspace/DL-healthcare/src/main.py", line 13, in <module>
    import seaborn as sns
ModuleNotFoundError: No module named 'seaborn'
root@d4a1a9ad5ff4:/workspace/DL-healthcare# pip install seaborn
Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com
Collecting seaborn
  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)
Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.24.4)
Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (2.2.2)
Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.9.2)
Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.0)
Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)
Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.54.1)
Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)
Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)
Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)
Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.4)
Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)
Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2023.4)
Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.1)
Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)
Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)
Installing collected packages: seaborn
Successfully installed seaborn-0.13.2
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.

[notice] A new release of pip is available: 24.2 -> 25.1.1
[notice] To update, run: python -m pip install --upgrade pip
root@d4a1a9ad5ff4:/workspace/DL-healthcare# python src/main.py
🚀 Using device: cuda
📱 Starting model training...
📊 Training for 30 epochs with 27972 batches per epoch.
Epoch 1/30: 100%|███████████████████████████████████████████████████████████████████████████████| 27972/27972 [07:23<00:00, 63.09it/s, loss=0.2043, accuracy=0.8214]
💚 Validation Loss after Epoch 1: 0.4872
Epoch 2/30: 100%|███████████████████████████████████████████████████████████████████████████████| 27972/27972 [07:36<00:00, 61.30it/s, loss=0.0396, accuracy=0.9640]
💚 Validation Loss after Epoch 2: 0.0398
Epoch 3/30: 100%|███████████████████████████████████████████████████████████████████████████████| 27972/27972 [07:30<00:00, 62.13it/s, loss=0.0192, accuracy=0.9876]
💚 Validation Loss after Epoch 3: 0.3564
Epoch 4/30: 100%|███████████████████████████████████████████████████████████████████████████████| 27972/27972 [07:46<00:00, 60.02it/s, loss=0.0158, accuracy=0.9893]
💚 Validation Loss after Epoch 4: 0.0279
Epoch 5/30: 100%|███████████████████████████████████████████████████████████████████████████████| 27972/27972 [06:51<00:00, 67.93it/s, loss=0.0259, accuracy=0.9898]
💚 Validation Loss after Epoch 5: 0.2177
Epoch 6/30: 100%|███████████████████████████████████████████████████████████████████████████████| 27972/27972 [04:58<00:00, 93.85it/s, loss=0.0402, accuracy=0.9902]
💚 Validation Loss after Epoch 6: 0.0267
Epoch 7/30: 100%|███████████████████████████████████████████████████████████████████████████████| 27972/27972 [04:44<00:00, 98.31it/s, loss=0.0453, accuracy=0.9909]
💚 Validation Loss after Epoch 7: 0.0259
Epoch 8/30: 100%|███████████████████████████████████████████████████████████████████████████████| 27972/27972 [04:46<00:00, 97.72it/s, loss=0.0161, accuracy=0.9919]
💚 Validation Loss after Epoch 8: 0.0250
Epoch 9/30: 100%|███████████████████████████████████████████████████████████████████████████████| 27972/27972 [04:51<00:00, 95.94it/s, loss=0.0245, accuracy=0.9922]
💚 Validation Loss after Epoch 9: 0.0259
Epoch 10/30: 100%|██████████████████████████████████████████████████████████████████████████████| 27972/27972 [04:58<00:00, 93.60it/s, loss=0.0422, accuracy=0.9925]
💚 Validation Loss after Epoch 10: 0.0228
Epoch 11/30: 100%|██████████████████████████████████████████████████████████████████████████████| 27972/27972 [04:59<00:00, 93.52it/s, loss=0.0237, accuracy=0.9929]
💚 Validation Loss after Epoch 11: 0.0228
Epoch 12/30: 100%|██████████████████████████████████████████████████████████████████████████████| 27972/27972 [04:44<00:00, 98.29it/s, loss=0.0416, accuracy=0.9932]
💚 Validation Loss after Epoch 12: 0.0229
Epoch 13/30: 100%|██████████████████████████████████████████████████████████████████████████████| 27972/27972 [05:22<00:00, 86.81it/s, loss=0.0143, accuracy=0.9934]
💚 Validation Loss after Epoch 13: 0.0206
Epoch 14/30: 100%|██████████████████████████████████████████████████████████████████████████████| 27972/27972 [06:38<00:00, 70.16it/s, loss=0.0119, accuracy=0.9934]
💚 Validation Loss after Epoch 14: 0.0231
Epoch 15/30: 100%|██████████████████████████████████████████████████████████████████████████████| 27972/27972 [06:40<00:00, 69.90it/s, loss=0.0429, accuracy=0.9935]
💚 Validation Loss after Epoch 15: 0.0234
Epoch 16/30: 100%|██████████████████████████████████████████████████████████████████████████████| 27972/27972 [06:42<00:00, 69.42it/s, loss=0.0089, accuracy=0.9935]
💚 Validation Loss after Epoch 16: 0.0206
Epoch 17/30: 100%|██████████████████████████████████████████████████████████████████████████████| 27972/27972 [07:02<00:00, 66.13it/s, loss=0.0367, accuracy=0.9935]
💚 Validation Loss after Epoch 17: 0.0213
Epoch 18/30: 100%|██████████████████████████████████████████████████████████████████████████████| 27972/27972 [07:17<00:00, 63.91it/s, loss=0.0138, accuracy=0.9936]
💚 Validation Loss after Epoch 18: 0.0227
Epoch 20/30: 100%|██████████████████████████████████████████████████████████████████████████████| 27972/27972 [07:33<00:00, 61.63it/s, loss=0.0181, accuracy=0.9937]
💚 Validation Loss after Epoch 20: 0.0226
Epoch 21/30: 100%|██████████████████████████████████████████████████████████████████████████████| 27972/27972 [07:47<00:00, 59.83it/s, loss=0.0243, accuracy=0.9937]
💚 Validation Loss after Epoch 21: 0.0242
⏹ Early stopping triggered.
/workspace/DL-healthcare/src/main.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(os.path.join(output_dir, "best_model.pth")))

🔍 Final Metrics on Test Set:
Accuracy: 0.9938
Precision: 0.9933
Recall: 0.9938
F1 Score: 0.9928

📊 Classification Report:
                          precision    recall  f1-score   support

                 Benign       0.93      0.98      0.95     80834
              DDoS-ICMP       1.00      1.00      1.00    649699
               DDoS-SYN       1.00      1.00      1.00    338140
               DDoS-TCP       1.00      1.00      1.00    340359
               DDoS-UDP       1.00      1.00      1.00    690743
               DoS-ICMP       1.00      1.00      1.00    176458
                DoS-SYN       1.00      1.00      1.00    186476
                DoS-TCP       1.00      1.00      1.00    160313
                DoS-UDP       1.00      1.00      1.00    240312
MQTT-DDoS-Connect_Flood       1.00      1.00      1.00     73354
MQTT-DDoS-Publish_Flood       1.00      0.93      0.96     11884
 MQTT-DoS-Connect_Flood       0.99      0.98      0.99      5381
 MQTT-DoS-Publish_Flood       0.96      1.00      0.98     18612
    MQTT-Malformed_Data       0.80      0.43      0.56      2245
          Recon-OS_Scan       0.74      0.08      0.15      7096
       Recon-Ping_Sweep       0.61      0.60      0.61       318
        Recon-Port_Scan       0.84      0.95      0.89     35926
          Recon-VulScan       0.65      0.17      0.27       971
               Spoofing       0.66      0.49      0.56      6630

               accuracy                           0.99   3025751
              macro avg       0.90      0.82      0.84   3025751
           weighted avg       0.99      0.99      0.99   3025751


🗙 Confusion Matrix:
 [[ 79500      0      0      0      0      0      0      0      1      0
       0      0      0    129      0     27    198     22    957]
 [     1 649536     10     31     52     34      0      0     35      0
       0      0      0      0      0      0      0      0      0]
 [     2    102 337760    114     51      7     90      3      9      0
       0      0      1      0      0      0      1      0      0]
 [     0     52     14 340147    121      8      1      7      8      0
       0      0      0      0      0      0      0      0      1]
 [     5     42      4     41 690449      5      0      0    197      0
       0      0      0      0      0      0      0      0      0]
 [     1    275      0      4     12 176064      5      4     93      0
       0      0      0      0      0      0      0      0      0]
 [     1      1    132      6     13     76 186097     21    129      0
       0      0      0      0      0      0      0      0      0]
 [     1      1      4    225      0     17     11 160033     20      0
       0      0      1      0      0      0      0      0      0]
 [     3      0      0      3    172    143      9     19 239963      0
       0      0      0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0  73285
       4     60      0      4      0      0      1      0      0]
 [     0      0      1      0      0      0      2      9      1     15
   11054      4    798      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      2      0     91
       0   5288      0      0      0      0      0      0      0]
 [     1      0      1      1      0      0      1      9      2      2
       4      0  18590      1      0      0      0      0      0]
 [  1064      0      0      0      0      0      0      0      0      0
       0      0      0    956      1      0      1      0    223]
 [   778      0      0      0      0      0      0      0      0      0
       0      0      0     31    584      0   5680     22      1]
 [   126      0      0      0      0      0      0      0      0      0
       0      0      0      0      0    192      0      0      0]
 [  1214      0      0      0      0      0      0      0      0      0
       0      0      0      3    175      0  34132     37    365]
 [   131      0      0      0      0      0      0      0      0      0
       0      0      0      5     26      0    518    168    123]
 [  2966      0      0      0      0      0      0      0      0      0
       0      0      0     60      0     97    271      9   3227]]